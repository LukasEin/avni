{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Get_Orig_Model(ModelFile,Depth_Interest): \n",
    "    \"\"\"Extracts original model from the .mat modelfile. Does this a slightly different way than for cubed faces,\n",
    "    since there are no basis functions involved here. \n",
    "    \"\"\"\n",
    "    ##Note that the ModelFile here has to follow the conventions as is imported from the .mat file \n",
    "    ##when generated from running the DVmatfile script in wavelets_matlab\n",
    "    Vvals = ModelFile['model']\n",
    "    Depth_Checker = np.nonzero(ModelFile['depth'] == (Depth_Interest))\n",
    "    DvDepthVals = Vvals[0,Depth_Checker]\n",
    "    ##orig. formulation above\n",
    "\n",
    "    Depth_Checker = np.nonzero(ModelFile['depth'] == (Depth_Interest))\n",
    "    DvDepthVals = Vvals[0,Depth_Checker]\n",
    "    Face1Map = DvDepthVals[0,0:len(DvDepthVals[0])/6]\n",
    "    Face2Map = DvDepthVals[0,len(DvDepthVals[0])/6:2*len(DvDepthVals[0])/6]\n",
    "    Face3Map = DvDepthVals[0,2*len(DvDepthVals[0])/6:3*len(DvDepthVals[0])/6]\n",
    "    Face4Map = DvDepthVals[0,3*len(DvDepthVals[0])/6:4*len(DvDepthVals[0])/6]\n",
    "    Face5Map = DvDepthVals[0,4*len(DvDepthVals[0])/6:5*len(DvDepthVals[0])/6]\n",
    "    Face6Map = DvDepthVals[0,5*len(DvDepthVals[0])/6:6*len(DvDepthVals[0])/6]\n",
    "    All_map = [Face1Map,Face2Map,Face3Map,Face4Map,Face5Map,Face6Map]\n",
    "    \n",
    "    return All_map\n",
    "\n",
    "def Get_RMS(ModelVals):\n",
    "    \"\"\"Quick elegant algorithm from stackexchange that gets rms of a vector. \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    rms = np.sqrt(np.mean((abs(ModelVals))**2 )) \n",
    "    return rms\n",
    "    \n",
    "def Get_Scale_Indices(Scale_Interest,GridName,Database_Path):\n",
    "    \"\"\"Simple search to get the indices corresponding to a specific scale. \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    Grids = sio.loadmat(Database_Path + GridName)\n",
    "    ##Find the indices on a single face \n",
    "    ##that correspond to a particular scale or set of scales. Best used with basis wavelet maps\n",
    "    for i in range(np.size(Scale_Interest)):\n",
    "            Temp_Scale_Checker = np.nonzero(Grids['ScaleIndex'][0,:] == (Scale_Interest[i]))\n",
    "            if i == 0:\n",
    "                Scale_Checker = Temp_Scale_Checker\n",
    "            elif i > 0:\n",
    "                Scale_Checker = np.concatenate([Scale_Checker,Temp_Scale_Checker],axis=1)\n",
    "    return(Scale_Checker)\n",
    "                \n",
    "def Get_Depth_Wavelet_Coeffs(ModelFile,Depth_Interest): \n",
    "    \"\"\"Simple search to get wavelet coefficients at a specified depth by using indexing given in the .mat file for the model.\n",
    "    \"\"\"\n",
    "    wvcoeffs = ModelFile['wvcoeffs']\n",
    "    Depth_Checker = np.nonzero(ModelFile['depth'] == (Depth_Interest))\n",
    "    Wavelet_CoeffsForADepth = wvcoeffs[0,Depth_Checker]\n",
    "    Wavelet_CoeffsForADepth = Wavelet_CoeffsForADepth[0]\n",
    "    return(Wavelet_CoeffsForADepth)\n",
    "    \n",
    "    \n",
    "def Construct_Face_Map_From_WaveletCoeffs(wvcoeffs,GridName,Modelfile,Depth_Interest,Scale_Interest,Database_Path,ModelBasisName,N):\n",
    "    \"\"\" This essentially runs the inverse wavelet transform but for all coefficients at a time. \n",
    "    This will probably be rendered useless in the future, but for now it iterates through all coefficients, multiplies them by the \n",
    "    corresponding basis function in the sparse map array, and then adds this to the full map. Does this separately for six faces by \n",
    "    checking if it belongs to the right face first!\n",
    "    \"\"\"\n",
    "    NumVals = int(6)*int(2)**(int(2)*int(N))\n",
    "    WaveletBasis = sio.loadmat(Database_Path + ModelBasisName)\n",
    "    Grids = sio.loadmat(Database_Path + GridName)\n",
    "    Depth_Coeffs = Get_Depth_Wavelet_Coeffs(Modelfile,Depth_Interest)\n",
    "    Scale_Checker = Get_Scale_Indices(Scale_Interest,GridName,Database_Path)\n",
    "    \n",
    "    Face1Map = 0;\n",
    "    Face2Map = 0;\n",
    "    Face3Map = 0;\n",
    "    Face4Map = 0;\n",
    "    Face5Map = 0;\n",
    "    Face6Map = 0;\n",
    "    \n",
    "    for i in range(len(Scale_Checker[0])):\n",
    "        Curr_Index = Scale_Checker[0][i] \n",
    "        Curr_BasisIndex = Curr_Index%(NumVals/6)\n",
    "\n",
    "                            #    Curr_Coeff = Depth_100_Coeffs[Curr_Index]\n",
    "        Curr_Coeff = Depth_Coeffs[Curr_Index]\n",
    "        if Grids['face'][Curr_Index] == 1:\n",
    "            Curr_Map = (WaveletBasis['Me'][0,Curr_BasisIndex][0].toarray())\n",
    "            Face1Map = Face1Map+Curr_Map*Curr_Coeff\n",
    "        elif Grids['face'][Curr_Index] == 2:\n",
    "            Curr_Map = (WaveletBasis['Me'][0,Curr_BasisIndex][0].toarray())\n",
    "            Face2Map = Face2Map+Curr_Map*Curr_Coeff\n",
    "        elif Grids['face'][Curr_Index] == 3:\n",
    "            Curr_Map = (WaveletBasis['Me'][0,Curr_BasisIndex][0].toarray())\n",
    "            Face3Map = Face3Map+Curr_Map*Curr_Coeff\n",
    "        elif Grids['face'][Curr_Index] == 4:\n",
    "            Curr_Map = (WaveletBasis['Me'][0,Curr_BasisIndex][0].toarray())\n",
    "            Face4Map = Face4Map+Curr_Map*Curr_Coeff\n",
    "        elif Grids['face'][Curr_Index] == 5:\n",
    "            Curr_Map = (WaveletBasis['Me'][0,Curr_BasisIndex][0].toarray())\n",
    "            Face5Map = Face5Map+Curr_Map*Curr_Coeff\n",
    "        elif Grids['face'][Curr_Index] == 6:\n",
    "            Curr_Map = (WaveletBasis['Me'][0,Curr_BasisIndex][0].toarray())\n",
    "            Face6Map = Face6Map+Curr_Map*Curr_Coeff\n",
    "\n",
    "    All_map =[(np.transpose(Face1Map)).flatten(),(np.transpose(Face2Map)).flatten(),(np.transpose(Face3Map)).flatten(),(np.transpose(Face4Map)).flatten(),(np.transpose(Face5Map)).flatten(),(np.transpose(Face6Map)).flatten()]\n",
    "    return(All_map)\n",
    "\n",
    "def RMS_of_Cubed_Sphere(All_map):\n",
    "    \"\"\"Calls an earlier RMS routine to get RMS across 6 faces on the cubed sphere after concatenating \n",
    "    and flattening data on all the faces. \n",
    "    \"\"\"\n",
    "    for i in range(len(All_map)):\n",
    "        if i == 0:\n",
    "            value = All_map[i]\n",
    "            value = np.transpose(value)\n",
    "            Fullvalue = value.flatten()\n",
    "        elif i > 0:\n",
    "            value = All_map[i]\n",
    "            value = np.transpose(value)\n",
    "            value = value.flatten()\n",
    "            Fullvalue = np.concatenate([Fullvalue,value],axis=0)\n",
    "    return(Get_RMS(Fullvalue))\n",
    "\n",
    "def Plot_Map (All_map,ax,input_title,WaveletBasis,Grids,colormaxinput):\n",
    "    \"\"\" Plots a robinson projection map of data in the inverse of the wavelet domain. \n",
    "    Assumes you've imported basemap and stuff. Also note that it plots by iterating over cubed faces,\n",
    "    so your input data should be in the format [face1 face2 face3 face4 face5 face6]\n",
    "    \"\"\"\n",
    "    Nbasis = len(WaveletBasis['Me'][0,:])\n",
    "    for i in range(len(All_map)):\n",
    "    #Plot a wavelet from a selected face\n",
    "        #print(i)\n",
    "\n",
    "        face = i\n",
    "        value = All_map[i]\n",
    "        value = np.transpose(value)\n",
    "        value = value.flatten()\n",
    "\n",
    "        N = Grids['MetaN'][0][0]\n",
    "        ScaleIndex = Grids['ScaleIndex'][0][0]\n",
    "        #print ScaleIndex\n",
    "        Jmax = Grids['MetaJmax'][0][0]\n",
    "        lonwav = Grids['lon'][face*Nbasis:(face+1)*Nbasis]\n",
    "        latwav = Grids['lat'][face*Nbasis:(face+1)*Nbasis]\n",
    "\n",
    "\n",
    "        # Define a colorscale\n",
    "        #colormax=np.amax(abs(value)) #(-colormax,colormax) are the limits of the colorbar (This varies with each face, too risky right now)\n",
    "        colormax= colormaxinput\n",
    "        greylimit=0.001*colormax  #this is the limit to which the middle color (grey) will extend on either side of colorttmax mid\n",
    "        name='r_lgrey_b'\n",
    "        c = colors.ColorConverter().to_rgb\n",
    "        colorlist=[c('red'), c('lightgray'), (2.*colormax-2.*greylimit)/(4.*colormax), c('lightgray'),c('lightgray'), (2.*colormax+2.*greylimit)/(4.*colormax), c('lightgray'),c('blue'), 1., c('blue')]\n",
    "        custom_cmap = make_colormap(colorlist,name)\n",
    "        register_cmap(name=custom_cmap.name, cmap=custom_cmap)\n",
    "        palette=custom_cmap.name\n",
    "\n",
    "        colorVal=get_colors(val=value,xmin=-colormax,xmax=colormax,palette=palette)\n",
    "        #print colorVal.shape,value.shape,lonwav.shape\n",
    "\n",
    "\n",
    "        # Make the figure\n",
    "\n",
    "        m = Basemap(projection='robin', lon_0=0,resolution='c',ax=ax)\n",
    "        m.drawcoastlines()\n",
    "        x, y = m(lonwav,latwav); \n",
    "        cm = get_cmap(palette)\n",
    "        sc = ax.scatter(x, y, c=colorVal, vmin=-colormax, vmax=colormax, edgecolor= '', cmap=cm)\n",
    "        #sc = ax.scatter(x, y, c=colorVal, vmin=-2, vmax=2, edgecolor= '', cmap=cm)\n",
    "\n",
    "        # Set title\n",
    "        titlestr  = input_title\n",
    "        #titlestr='N='+str(N)+', Jmax='+str(Jmax)+ ',Depth='+str(6371-Depth_Interest)+',Scales Used:'+str(Scale_Interest)#'+str(face+1),\n",
    "        ax.set_title(titlestr,fontsize=12)\n",
    "\n",
    "        # draw parallels and meridians.\n",
    "        # labels = [left,right,top,bottom]\n",
    "        parallels = np.arange(-60,90,30.)\n",
    "        m.drawparallels(parallels,labels=[False,True,False,False])\n",
    "        meridians = np.arange(0.,360.,90.)\n",
    "        m.drawmeridians(meridians,labels=[False,False,False,True])\n",
    "    return(ax)\n",
    "\n",
    "def Get_Scale_Coeffs (ModelFile,Scale_Interest,GridName,Database_Path,Depth_Interest):\n",
    "    \"\"\" This uses other routines to extract the exact wavelet coefficients which correspond to a \n",
    "    specific scale of interest. Assumes files have been read in in earlier blocks!     \n",
    "    \"\"\"\n",
    "    Coeff_List = [];\n",
    "    Model_ScaleIndices =  Get_Scale_Indices(ModelFile,Scale_Interest,GridName,Database_Path)\n",
    "    Model_Depth_Coeffs = Get_Depth_Wavelet_Coeffs(ModelFile,Depth_Interest)\n",
    "    for i in range(len(Model_ScaleIndices[0])):\n",
    "        Curr_Index = Model_ScaleIndices[0][i] \n",
    "        Curr_Coeff = Model_Depth_Coeffs[Curr_Index]                \n",
    "        Coeff_List.append(Curr_Coeff)\n",
    "\n",
    "\n",
    "    return(Coeff_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
